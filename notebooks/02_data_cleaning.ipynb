{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa9eea90-81ad-4704-9c44-960f6464d217",
   "metadata": {},
   "source": [
    "***************************************************************************************\n",
    "Jupyter Notebooks from the Metadata for Everyone project\n",
    "\n",
    "Code:\n",
    "* Dennis Donathan II (https://orcid.org/0000-0001-8042-0539)\n",
    "\n",
    "Project team: \n",
    "* Juan Pablo Alperin (https://orcid.org/0000-0002-9344-7439)\n",
    "* Dennis Donathan II (https://orcid.org/0000-0001-8042-0539)\n",
    "* Mike Nason (https://orcid.org/0000-0001-5527-8489)\n",
    "* Julie Shi (https://orcid.org/0000-0003-1242-1112)\n",
    "* Marco Tullney (https://orcid.org/0000-0002-5111-2788)\n",
    "\n",
    "Last updated: xxx\n",
    "***************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01402dd8",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "The raw csv consists of 3 columns:\n",
    "\n",
    "* Index\n",
    "\n",
    "* DOI\n",
    "\n",
    "* XML\n",
    "\n",
    "The XML record has a lot of information, but not all is relevant for this study. We will extract from each record the metadata that is relevant and then format it in a nested dictionary. The resulting dictionary's schema looks like this:\n",
    "\n",
    "```\n",
    "{\n",
    "    'doi': str | None,\n",
    "    'authors': list[dict[given_name, surname, sequence, affiliation]] | None,\n",
    "    'abstracts': list[str] | None,\n",
    "    'journal_lang': str | None,\n",
    "    'article_lang': str | None,\n",
    "    'abstract_langs': list[str] | None,\n",
    "    'publisher_name': str | None,\n",
    "    'journal_title': str | None,\n",
    "    'article_title': str | None\n",
    "    }\n",
    "```\n",
    "Due to the size of the dataset, we'll use [Dask](https://docs.dask.org/en/stable/index.html) to load in the csv and preform the metadata extraction functions defined below. Depending on the hardware resources, the time to load in the data and preform the extraction can vary. The parameter `blocksize=250MB` found within the `df` variable in the `clean_csv` function can be altered accordingly. 250MB is a somewhat neutral value in that most computing systems can run the code comfortably, but it will take multiple hours to run.\n",
    "\n",
    "Now we will load in our packages and set up our paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dfabfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Set up directories\n",
    "data_dir = Path('../data')\n",
    "input_dir = data_dir / 'input'\n",
    "output_dir = data_dir / 'output'\n",
    "\n",
    "csv_path = input_dir / 'allv3.csv'\n",
    "parquet_path = input_dir / '02_cleaned_data.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb951f1",
   "metadata": {},
   "source": [
    "## Extraction Functions\n",
    "\n",
    "Each function is named according to which piece of metadata it will extract. Then they are all called within the `__metadata` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560558c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __authors(soup: 'bs4.BeautifulSoup') -> list[dict] | None:\n",
    "    \"\"\"Helper function to extract relevant author metadata from\n",
    "    XML records.\n",
    "\n",
    "    Args:\n",
    "        record (str): An individual metadata record in XML format.\n",
    "\n",
    "    Returns:\n",
    "        list[dict] | None : A list of nested dictionaries containing the relevant author metadata.\n",
    "                            If no authors are present, None is returned.\n",
    "    \"\"\"\n",
    "    author_list = []\n",
    "    #soup = BeautifulSoup(record, 'xml')\n",
    "    authors = soup.find('contributors')\n",
    "    if authors:\n",
    "        first_authors = authors.find_all('person_name', sequence='first')\n",
    "        additional_authors = authors.find_all('person_name', sequence='additional')\n",
    "        for i in first_authors:\n",
    "            name_dict = {\n",
    "                'given_name': None,\n",
    "                'surname': None,\n",
    "                'sequence': None,\n",
    "                'affiliation': None\n",
    "            }\n",
    "            for k in name_dict:\n",
    "                if k =='sequence':\n",
    "                    name_dict[k] = 'first'\n",
    "                else:\n",
    "                    if i.find(k):\n",
    "                        name_dict[k] = i.find(k).get_text()\n",
    "                    else:\n",
    "                        continue\n",
    "            author_list.append(name_dict)\n",
    "        for i in additional_authors:\n",
    "            name_dict = {\n",
    "                'given_name': None,\n",
    "                'surname': None,\n",
    "                'sequence': None,\n",
    "                'affiliation': None\n",
    "            }\n",
    "            for k in name_dict:\n",
    "                if k =='sequence':\n",
    "                    name_dict[k] = 'additional'\n",
    "                else:\n",
    "                    if i.find(k):\n",
    "                        name_dict[k] = i.find(k).get_text()\n",
    "                    else:\n",
    "                        continue\n",
    "            author_list.append(name_dict)\n",
    "    if len(author_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return author_list\n",
    "    \n",
    "def __abstracts(soup: 'bs4.BeautifulSoup') -> list[str] | None:\n",
    "    \"\"\"Helper function that extracts all abstracts from XML records.\n",
    "\n",
    "    Args:\n",
    "        record (str): An individual metadata record in XML format.\n",
    "\n",
    "    Returns:\n",
    "        list[str] | None: Returns a list of all abstracts within a record.\n",
    "                        If there is no abstract within a record,\n",
    "                        then None is returned.\n",
    "    \"\"\"\n",
    "    #soup = BeautifulSoup(record, 'xml')\n",
    "    abstracts = soup.find_all('jats:abstract')\n",
    "    text = []\n",
    "    if abstracts:\n",
    "        for i in abstracts:\n",
    "            text.append(i.get_text())\n",
    "    else:\n",
    "        return None\n",
    "    return text\n",
    "\n",
    "def __languages(soup: 'bs4.BeautifulSoup') -> dict:\n",
    "    \"\"\"Helper function that extracts Language codes from multiple fields \n",
    "    within an XML record\n",
    "\n",
    "    Args:\n",
    "        record (str): An individual metadata record in XML format.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the language codes for three \n",
    "            different metadata fields.\n",
    "    \"\"\"\n",
    "    ret = {}\n",
    "    try: \n",
    "        #soup = BeautifulSoup(record, 'xml')\n",
    "        journal = soup.find('journal_metadata')\n",
    "        if journal:\n",
    "            ret['journal_lang'] = journal.get('language')\n",
    "        else:\n",
    "            ret['journal_lang'] = None\n",
    "            \n",
    "        article = soup.find('journal_article')\n",
    "        if article: \n",
    "            ret['article_lang'] = article.get('language')\n",
    "        else:\n",
    "            ret['article_lang'] = None\n",
    "\n",
    "        abstracts = soup.find_all('jats:abstract')\n",
    "        if abstracts: \n",
    "            langs = []\n",
    "            for abstract in abstracts: \n",
    "                langs.append(abstract.get('xml:lang'))\n",
    "                langs = [l for l in langs if l is not None]\n",
    "                \n",
    "            if len(langs) == 0:\n",
    "                langs = None\n",
    "            ret['abstract_langs'] = langs\n",
    "        else:\n",
    "            ret['abstract_langs'] = None\n",
    "            \n",
    "    except Exception as e:\n",
    "        ret['err'] = type(e).__name__\n",
    "\n",
    "    return ret\n",
    "\n",
    "def __titles(soup: 'bs4.BeautifulSoup') -> dict | None:\n",
    "    \"\"\"Helper function to extract various titles from XML records.\n",
    "\n",
    "    Args:\n",
    "        record (str): An individual metadata record in XML format.\n",
    "\n",
    "    Returns:\n",
    "        dict | None: A dictionary containing titles and labels, or None\n",
    "                    if no titles are present.\n",
    "    \"\"\" \n",
    "    #soup = BeautifulSoup(record, 'xml')\n",
    "    titles = {}\n",
    "    try:\n",
    "        publisher = soup.find('crm-item', attrs={'name': 'publisher-name'})\n",
    "        if publisher:\n",
    "            titles['publisher_name'] = publisher.get_text()\n",
    "        else:\n",
    "            titles['publisher_name'] = None\n",
    "        journal = soup.find('journal_metadata')\n",
    "        if journal:\n",
    "            titles['journal_title'] = journal.find('full_title').get_text()\n",
    "        else:\n",
    "            titles['journal_title'] = None\n",
    "        article = soup.find('titles')\n",
    "        if article:\n",
    "            article = article.find_all('title')\n",
    "            titles['article_title'] = [i.get_text() for i in article]\n",
    "        else:\n",
    "            titles['article_title'] = None\n",
    "        return titles\n",
    "    except Exception as err:\n",
    "        return err\n",
    "\n",
    "def __metadata(record: str) -> dict:\n",
    "    try:\n",
    "        soup = BeautifulSoup(record, 'xml')\n",
    "        doi = soup.find('doi')\n",
    "        authors = __authors(soup)\n",
    "        abstracts = __abstracts(soup)\n",
    "        languages = __languages(soup)\n",
    "        titles = __titles(soup)\n",
    "        final_record = {'doi': doi.get_text() if doi else None,\n",
    "                        'authors': authors,\n",
    "                        'abstracts': abstracts,\n",
    "                        'journal_lang': languages['journal_lang'],\n",
    "                        'article_lang': languages['article_lang'],\n",
    "                        'abstract_langs': languages['abstract_langs'],\n",
    "                        'publisher_name': titles['publisher_name'],\n",
    "                        'journal_title': titles['journal_title'],\n",
    "                        'article_title': titles['article_title']}\n",
    "        return final_record\n",
    "    except TypeError as err:\n",
    "        if type(record) == 'NAType':\n",
    "            return None\n",
    "        else:\n",
    "            print(err)\n",
    "\n",
    "\n",
    "def clean_csv(csv_path: str, metadata_parquet_path: str):\n",
    "    # Here is the df variable containing the blocksize parameter.\n",
    "    df = dd.read_csv(csv_path, names=['index', 'DOI', 'xml'], blocksize='250MB')\n",
    "    metadata = df['xml'].map(__metadata, meta=('metadata', 'object')).compute()\n",
    "    metadata_df = pd.DataFrame(metadata)\n",
    "    metadata_df.to_parquet(metadata_parquet_path, index=False)\n",
    "    return metadata_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49fed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell runs the functions and saves the new data to a parquet.\n",
    "Depending on the value set in the blocksize parameter,\n",
    "this may take some time.\n",
    "\"\"\"\n",
    "\n",
    "df = clean_csv(csv_path, parquet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "447af80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(parquet_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f6cc2f",
   "metadata": {},
   "source": [
    "## Conferences\n",
    "There are a couple 'Conferences' and 'Proceedings' in the *journal_title* column. Let's take a look at just how many records remain in our dataset are from these journals/containers.\n",
    "\n",
    "Additionally, we see a few records from the journal *ChemInform*, a journal that publishes chemistry abstracts, we'll check to see if any of those records remain as well.\n",
    "\n",
    "We'll use a keyword search in the *journal_title* column to find these records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dbf5ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_langs</th>\n",
       "      <th>abstracts</th>\n",
       "      <th>article_lang</th>\n",
       "      <th>article_title</th>\n",
       "      <th>authors</th>\n",
       "      <th>doi</th>\n",
       "      <th>journal_lang</th>\n",
       "      <th>journal_title</th>\n",
       "      <th>publisher_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[en]</td>\n",
       "      <td>[ Abstract ChemInform is a weekly Abstracting ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[ChemInform Abstract: Reactions of Polychloro ...</td>\n",
       "      <td>[{'affiliation': None, 'given_name': 'A. P.', ...</td>\n",
       "      <td>10.1002/chin.200015092</td>\n",
       "      <td>en</td>\n",
       "      <td>ChemInform</td>\n",
       "      <td>Wiley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Localization method of robot by TOF laser sen...</td>\n",
       "      <td>[{'affiliation': 'Hiroshima City University', ...</td>\n",
       "      <td>10.1299/jsmermd.2020.2A2-D14</td>\n",
       "      <td>en</td>\n",
       "      <td>The Proceedings of JSME annual Conference on R...</td>\n",
       "      <td>Japan Society of Mechanical Engineers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[en]</td>\n",
       "      <td>[ Abstract ChemInform is a weekly Abstracting ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[ChemInform Abstract: Structure of 1,2‐Dipheny...</td>\n",
       "      <td>[{'affiliation': None, 'given_name': 'Z. G.', ...</td>\n",
       "      <td>10.1002/chin.199331044</td>\n",
       "      <td>en</td>\n",
       "      <td>ChemInform</td>\n",
       "      <td>Wiley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>[en]</td>\n",
       "      <td>[                     In order to quantitative...</td>\n",
       "      <td>en</td>\n",
       "      <td>[                    Formation damage due to a...</td>\n",
       "      <td>[{'affiliation': None, 'given_name': 'Kun', 'n...</td>\n",
       "      <td>10.2516/ogst/2018084</td>\n",
       "      <td>None</td>\n",
       "      <td>Oil &amp; Gas Science and Technology – Revue d’IFP...</td>\n",
       "      <td>EDP Sciences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[10.31030/2286699]</td>\n",
       "      <td>None</td>\n",
       "      <td>10.31030/2286699</td>\n",
       "      <td>en</td>\n",
       "      <td>CrossRef Listing of Deleted DOIs</td>\n",
       "      <td>Test accounts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529821</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Development of Computer Network Security Base...</td>\n",
       "      <td>[{'affiliation': None, 'given_name': 'Yizhi', ...</td>\n",
       "      <td>10.1088/1742-6596/2037/1/012054</td>\n",
       "      <td>None</td>\n",
       "      <td>Journal of Physics: Conference Series</td>\n",
       "      <td>IOP Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529870</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>[                    Prompt fission           ...</td>\n",
       "      <td>[{'affiliation': None, 'given_name': 'Stephan'...</td>\n",
       "      <td>10.1051/epjconf/201714604060</td>\n",
       "      <td>None</td>\n",
       "      <td>EPJ Web of Conferences</td>\n",
       "      <td>EDP Sciences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529902</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Expanding Medicaid coverage − a lottery worth...</td>\n",
       "      <td>None</td>\n",
       "      <td>10.1007/s40274-013-0387-5</td>\n",
       "      <td>en</td>\n",
       "      <td>PharmacoEconomics &amp; Outcomes News</td>\n",
       "      <td>Springer Science and Business Media LLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529911</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>fr</td>\n",
       "      <td>[Résistance électrique des solénoides pour des...</td>\n",
       "      <td>[{'affiliation': None, 'given_name': 'A.', 'na...</td>\n",
       "      <td>10.1051/jphystap:01908007006200</td>\n",
       "      <td>None</td>\n",
       "      <td>Journal de Physique Théorique et Appliquée</td>\n",
       "      <td>EDP Sciences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529957</th>\n",
       "      <td>[en]</td>\n",
       "      <td>[ Abstract ChemInform is a weekly Abstracting ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[ChemInform Abstract: Nonpeptide Glycoprotein ...</td>\n",
       "      <td>[{'affiliation': None, 'given_name': 'N. J.', ...</td>\n",
       "      <td>10.1002/chin.199824135</td>\n",
       "      <td>en</td>\n",
       "      <td>ChemInform</td>\n",
       "      <td>Wiley</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10379 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abstract_langs                                          abstracts  \\\n",
       "7                [en]  [ Abstract ChemInform is a weekly Abstracting ...   \n",
       "43               None                                               None   \n",
       "98               [en]  [ Abstract ChemInform is a weekly Abstracting ...   \n",
       "104              [en]  [                     In order to quantitative...   \n",
       "189              None                                               None   \n",
       "...               ...                                                ...   \n",
       "529821           None                                               None   \n",
       "529870           None                                               None   \n",
       "529902           None                                               None   \n",
       "529911           None                                               None   \n",
       "529957           [en]  [ Abstract ChemInform is a weekly Abstracting ...   \n",
       "\n",
       "       article_lang                                      article_title  \\\n",
       "7              None  [ChemInform Abstract: Reactions of Polychloro ...   \n",
       "43             None  [Localization method of robot by TOF laser sen...   \n",
       "98             None  [ChemInform Abstract: Structure of 1,2‐Dipheny...   \n",
       "104              en  [                    Formation damage due to a...   \n",
       "189            None                                 [10.31030/2286699]   \n",
       "...             ...                                                ...   \n",
       "529821         None  [Development of Computer Network Security Base...   \n",
       "529870           en  [                    Prompt fission           ...   \n",
       "529902         None  [Expanding Medicaid coverage − a lottery worth...   \n",
       "529911           fr  [Résistance électrique des solénoides pour des...   \n",
       "529957         None  [ChemInform Abstract: Nonpeptide Glycoprotein ...   \n",
       "\n",
       "                                                  authors  \\\n",
       "7       [{'affiliation': None, 'given_name': 'A. P.', ...   \n",
       "43      [{'affiliation': 'Hiroshima City University', ...   \n",
       "98      [{'affiliation': None, 'given_name': 'Z. G.', ...   \n",
       "104     [{'affiliation': None, 'given_name': 'Kun', 'n...   \n",
       "189                                                  None   \n",
       "...                                                   ...   \n",
       "529821  [{'affiliation': None, 'given_name': 'Yizhi', ...   \n",
       "529870  [{'affiliation': None, 'given_name': 'Stephan'...   \n",
       "529902                                               None   \n",
       "529911  [{'affiliation': None, 'given_name': 'A.', 'na...   \n",
       "529957  [{'affiliation': None, 'given_name': 'N. J.', ...   \n",
       "\n",
       "                                    doi journal_lang  \\\n",
       "7                10.1002/chin.200015092           en   \n",
       "43         10.1299/jsmermd.2020.2A2-D14           en   \n",
       "98               10.1002/chin.199331044           en   \n",
       "104                10.2516/ogst/2018084         None   \n",
       "189                    10.31030/2286699           en   \n",
       "...                                 ...          ...   \n",
       "529821  10.1088/1742-6596/2037/1/012054         None   \n",
       "529870     10.1051/epjconf/201714604060         None   \n",
       "529902        10.1007/s40274-013-0387-5           en   \n",
       "529911  10.1051/jphystap:01908007006200         None   \n",
       "529957           10.1002/chin.199824135           en   \n",
       "\n",
       "                                            journal_title  \\\n",
       "7                                              ChemInform   \n",
       "43      The Proceedings of JSME annual Conference on R...   \n",
       "98                                             ChemInform   \n",
       "104     Oil & Gas Science and Technology – Revue d’IFP...   \n",
       "189                      CrossRef Listing of Deleted DOIs   \n",
       "...                                                   ...   \n",
       "529821              Journal of Physics: Conference Series   \n",
       "529870                             EPJ Web of Conferences   \n",
       "529902                  PharmacoEconomics & Outcomes News   \n",
       "529911         Journal de Physique Théorique et Appliquée   \n",
       "529957                                         ChemInform   \n",
       "\n",
       "                                 publisher_name  \n",
       "7                                         Wiley  \n",
       "43        Japan Society of Mechanical Engineers  \n",
       "98                                        Wiley  \n",
       "104                                EDP Sciences  \n",
       "189                               Test accounts  \n",
       "...                                         ...  \n",
       "529821                           IOP Publishing  \n",
       "529870                             EDP Sciences  \n",
       "529902  Springer Science and Business Media LLC  \n",
       "529911                             EDP Sciences  \n",
       "529957                                    Wiley  \n",
       "\n",
       "[10379 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conferences = df.loc[(df.journal_title.str.contains(r'conference|ChemInform|news|CrossRef Listing of Deleted DOIs', \n",
    "                                                    regex=True, case=False)) |\n",
    "                                                    (df.publisher_name == 'EDP Sciences')]\n",
    "conferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1d86b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(519665, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(conferences.index, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bb49e1",
   "metadata": {},
   "source": [
    "Looks great! Now we'll save our cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "827651bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(parquet_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
