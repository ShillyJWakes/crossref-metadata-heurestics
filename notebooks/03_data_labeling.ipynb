{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09cc80c3-8b6d-4d0a-b9eb-8f4a7ae7c5a7",
   "metadata": {},
   "source": [
    "***************************************************************************************\n",
    "Jupyter Notebooks from the Metadata for Everyone project\n",
    "\n",
    "Code:\n",
    "* Dennis Donathan II (https://orcid.org/0000-0001-8042-0539)\n",
    "\n",
    "Project team: \n",
    "* Juan Pablo Alperin (https://orcid.org/0000-0002-9344-7439)\n",
    "* Dennis Donathan II (https://orcid.org/0000-0001-8042-0539)\n",
    "* Mike Nason (https://orcid.org/0000-0001-5527-8489)\n",
    "* Julie Shi (https://orcid.org/0000-0003-1242-1112)\n",
    "* Marco Tullney (https://orcid.org/0000-0002-5111-2788)\n",
    "\n",
    "Last updated: 2024-08-02\n",
    "***************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b4b47f",
   "metadata": {},
   "source": [
    "# Labeling Problems in the Data\n",
    "\n",
    "We identified many issues in Phase 1 of our project (see Shi, J., Nason, M., Tullney, M., & Alperin, J. P. (2023). Identifying Metadata Quality Issues Across Cultures. SocArXiv. https://doi.org/10.31235/osf.io/6fykh). Now we will go through and programatically label the records in this sample if they contain some of those issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e00c59-76ad-4e3c-acc7-7b8a7d2f7943",
   "metadata": {},
   "source": [
    "Start by importing the packages we'll need, setting up our directories, and loading in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01df98ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #Creating dataframe and manipulating data\n",
    "from bs4 import BeautifulSoup as bs # for cleaning xml tags\n",
    "import re #regular expressions used for detection of initials\n",
    "from py3langid.langid import LanguageIdentifier, MODEL_FILE #For language detection\n",
    "from nltk.tokenize import sent_tokenize #Tokenizing abstracts during language detection\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b4e4f1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_langs</th>\n",
       "      <th>abstracts</th>\n",
       "      <th>article_lang</th>\n",
       "      <th>article_title</th>\n",
       "      <th>authors</th>\n",
       "      <th>doi</th>\n",
       "      <th>journal_lang</th>\n",
       "      <th>journal_title</th>\n",
       "      <th>publisher_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Revolving Boot Crimping Machine]</td>\n",
       "      <td>None</td>\n",
       "      <td>10.1038/scientificamerican04281849-249k</td>\n",
       "      <td>None</td>\n",
       "      <td>Scientific American</td>\n",
       "      <td>Springer Science and Business Media LLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Development of Desktop CNC Lathe with Pipe Fr...</td>\n",
       "      <td>[{'affiliation': None, 'given_name': 'Naohiko'...</td>\n",
       "      <td>10.2493/jjspe.85.189</td>\n",
       "      <td>en</td>\n",
       "      <td>Journal of the Japan Society for Precision Eng...</td>\n",
       "      <td>Japan Society for Precision Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[0547 Predicting Response to Oral Appliance Th...</td>\n",
       "      <td>[{'affiliation': 'Zephyr Sleep Technologies, C...</td>\n",
       "      <td>10.1093/sleep/zsy061.546</td>\n",
       "      <td>en</td>\n",
       "      <td>Sleep</td>\n",
       "      <td>Oxford University Press (OUP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Anomalous absorption of hydrogen peroxide (H2...</td>\n",
       "      <td>[{'affiliation': None, 'given_name': 'Mohit K....</td>\n",
       "      <td>10.1016/j.jqsrt.2020.107085</td>\n",
       "      <td>en</td>\n",
       "      <td>Journal of Quantitative Spectroscopy and Radia...</td>\n",
       "      <td>Elsevier BV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Cultura emprendedora de los estudiantes de Ma...</td>\n",
       "      <td>[{'affiliation': None, 'given_name': None, 'na...</td>\n",
       "      <td>10.24265/iggp.2020.v7n1.09</td>\n",
       "      <td>None</td>\n",
       "      <td>Revista en Gobierno y Gestión Pública</td>\n",
       "      <td>Universidad de San Martin de Porres</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_langs abstracts article_lang  \\\n",
       "0           None      None         None   \n",
       "1           None      None         None   \n",
       "2           None      None         None   \n",
       "3           None      None         None   \n",
       "4           None      None         None   \n",
       "\n",
       "                                       article_title  \\\n",
       "0                  [Revolving Boot Crimping Machine]   \n",
       "1  [Development of Desktop CNC Lathe with Pipe Fr...   \n",
       "2  [0547 Predicting Response to Oral Appliance Th...   \n",
       "3  [Anomalous absorption of hydrogen peroxide (H2...   \n",
       "4  [Cultura emprendedora de los estudiantes de Ma...   \n",
       "\n",
       "                                             authors  \\\n",
       "0                                               None   \n",
       "1  [{'affiliation': None, 'given_name': 'Naohiko'...   \n",
       "2  [{'affiliation': 'Zephyr Sleep Technologies, C...   \n",
       "3  [{'affiliation': None, 'given_name': 'Mohit K....   \n",
       "4  [{'affiliation': None, 'given_name': None, 'na...   \n",
       "\n",
       "                                       doi journal_lang  \\\n",
       "0  10.1038/scientificamerican04281849-249k         None   \n",
       "1                     10.2493/jjspe.85.189           en   \n",
       "2                 10.1093/sleep/zsy061.546           en   \n",
       "3              10.1016/j.jqsrt.2020.107085           en   \n",
       "4               10.24265/iggp.2020.v7n1.09         None   \n",
       "\n",
       "                                       journal_title  \\\n",
       "0                                Scientific American   \n",
       "1  Journal of the Japan Society for Precision Eng...   \n",
       "2                                              Sleep   \n",
       "3  Journal of Quantitative Spectroscopy and Radia...   \n",
       "4              Revista en Gobierno y Gestión Pública   \n",
       "\n",
       "                            publisher_name  \n",
       "0  Springer Science and Business Media LLC  \n",
       "1  Japan Society for Precision Engineering  \n",
       "2            Oxford University Press (OUP)  \n",
       "3                              Elsevier BV  \n",
       "4      Universidad de San Martin de Porres  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Directory\n",
    "data_dir = Path('../data')\n",
    "input_dir = data_dir / 'input'\n",
    "output_dir = data_dir / 'output'\n",
    "# Loading in dataset\n",
    "df = pd.read_parquet(input_dir / '02_cleaned_data.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a762d8",
   "metadata": {},
   "source": [
    "## Missing Values in Common Fields\n",
    "This is a relatively easy problem to label, so we'll tackle these first.\n",
    "\n",
    "We'll set up a column *'no_author'* and assign `0` to all of the records. Then we will locate the records missing an author and change their value to `1`.\n",
    "\n",
    "Then we'll do the same for the *language, abstract,* and *title* fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1280f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Authors\n",
    "df['Author Missing'] = float(0)\n",
    "df.loc[df.authors.isna(), 'Author Missing'] = float(1)\n",
    "#Languages\n",
    "df['Article Language Missing'] = float(0)\n",
    "df.loc[df.article_lang.isna(), 'Article Language Missing'] = float(1)\n",
    "df['Journal Language Missing'] = float(0)\n",
    "df.loc[df.journal_lang.isna(), 'Journal Language Missing'] = float(1)\n",
    "#Abstracts\n",
    "df['Abstract Missing'] = float(0)\n",
    "df.loc[df.abstracts.isna(), 'Abstract Missing'] = float(1)\n",
    "#Titles\n",
    "df['Article Title Missing'] = float(0)\n",
    "df.loc[df.article_title.isna(), 'Article Title Missing'] = float(1)\n",
    "df['Journal Title Missing'] = float(0)\n",
    "df.loc[df.journal_title.isna(), 'Journal Title Missing'] = float(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad21ac6c-d4b3-4874-9933-c7bfb8cc7512",
   "metadata": {},
   "source": [
    "## Prevalence of missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab9c71b-220f-4150-a154-422368019663",
   "metadata": {},
   "source": [
    "### Missing Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fef1cf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.76 percent of the article records do not contain an author\n",
      "Number of records:  51707\n"
     ]
    }
   ],
   "source": [
    "prevalence_AuMis = (len(df.loc[df['Author Missing'] == 1])/len(df)) * 100\n",
    "#prevalence_AuMis # percentage of records with this specific issue\n",
    "print(\"{:0.2f} percent of the article records do not contain an author\".format(prevalence_AuMis))\n",
    "print(\"Number of records: \",len(df.loc[df['Author Missing'] ==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d4b4f61-bc0e-481d-8a08-d35be5be05f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing_authors_df = df.loc[df.no_author == 1]\n",
    "#missing_authors_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c51531-5f27-4f18-8607-46696b3c9797",
   "metadata": {},
   "source": [
    "### Missing Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ac205d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.49 percent of the article records do not have an article language specified\n",
      "Number of records:  506145\n"
     ]
    }
   ],
   "source": [
    "prevalence_Article_Lang_Miss = (len(df.loc[df['Article Language Missing'] == 1])/len(df)) * 100\n",
    "#prevalence_LangMis # percentage of records with this specific issue\n",
    "print(\"{:0.2f} percent of the article records do not have an article language specified\".format(prevalence_Article_Lang_Miss))\n",
    "print(\"Number of records: \",len(df.loc[df['Article Language Missing'] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab144586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.33 percent of the article records do not have an journal language specified\n",
      "Number of records:  113070\n"
     ]
    }
   ],
   "source": [
    "prevalence_Journal_Lang_Miss = (len(df.loc[df['Journal Language Missing'] == 1])/len(df)) * 100\n",
    "#prevalence_LangMis # percentage of records with this specific issue\n",
    "print(\"{:0.2f} percent of the article records do not have an journal language specified\".format(prevalence_Journal_Lang_Miss))\n",
    "print(\"Number of records: \",len(df.loc[df['Journal Language Missing'] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e59a2c6-2f54-4fa3-8562-207634d2c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing_language_df = df.loc[df.no_language == 1]\n",
    "#missing_language_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdba13a2-b553-4b74-b42a-21cb65c826c0",
   "metadata": {},
   "source": [
    "### Missing Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15a7a6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.45 percent of the article records do not contain an abstract\n",
      "Number of records:  399935\n"
     ]
    }
   ],
   "source": [
    "prevalence_AbsMis = (len(df.loc[df['Abstract Missing'] == 1])/len(df)) * 100\n",
    "#prevalence_AbsMis\n",
    "print(\"{:0.2f} percent of the article records do not contain an abstract\".format(prevalence_AbsMis))\n",
    "print(\"Number of records: \",len(df.loc[df['Abstract Missing'] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92fa167a-bfbc-429d-b92b-5827749a2644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing_abstract_df = df.loc[df.no_abstract == 1]\n",
    "#missing_abstract_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cba29df-245e-4b65-95a9-5b64a1642060",
   "metadata": {},
   "source": [
    "### Missing Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "329e407d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28 percent of the article records do not contain an article title\n",
      "Number of records:  1473\n"
     ]
    }
   ],
   "source": [
    "prevalence_Article_Title_Mis = (len(df.loc[df['Article Title Missing'] == 1])/len(df)) * 100\n",
    "#prevalence_TitleMis\n",
    "print(\"{:0.2f} percent of the article records do not contain an article title\".format(prevalence_Article_Title_Mis))\n",
    "print(\"Number of records: \",len(df.loc[df['Article Title Missing'] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "976e2e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 percent of the article records do not contain a Journal title\n",
      "Number of records:  2\n"
     ]
    }
   ],
   "source": [
    "prevalence_Journal_Title_Mis = (len(df.loc[df['Journal Title Missing'] == 1])/len(df)) * 100\n",
    "#prevalence_TitleMis\n",
    "print(\"{:0.2f} percent of the article records do not contain a Journal title\".format(prevalence_Journal_Title_Mis))\n",
    "print(\"Number of records: \",len(df.loc[df['Journal Title Missing'] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7473f2f9-7769-4648-822b-a7ac2dde6fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing_titles_df = df.loc[df.no_title == 1]\n",
    "#missing_titles_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf35788-a644-498a-8a0a-00ee8615aa68",
   "metadata": {},
   "source": [
    "## Investigating the Author Entries\n",
    "\n",
    "We'll start off by investigating the *author* field. This is an area that was found to have a number of potentially high priority issues as it pertains to social and political matters, as well as a field that has seen the some of the most pervasive issues in standardization. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe43966",
   "metadata": {},
   "source": [
    "## Author Sequence\n",
    "Our first function will be checking the *sequence* sub-field within the *author* field. This is the field wherein authors are either listed as 'first' or 'addtional'. This function sets up a counter then iterates through the author list of a record to check what the noted sequence is for each author.\n",
    "\n",
    "The `try` block filters out records that have no authors listed. After that we begin to iterate through each author within a given record.\n",
    "\n",
    "`If 'name' in author.keys():` is used to filter out institutions listed as authors as using the 'name' key is often how an institution is presented as an author within the metadata record. The code within the `if` block simply says if there's an institution as an author and they are the only author listed, increase the counter to 1, then the code will continue down to the `return` statements where **0** will be returned as technically there is not an issue with sequence in that record.\n",
    "\n",
    "`else: if author['sequence'] == 'first'` block is where the bulk of the counting activity will happen. Up until this point we are mostly filtering out instances that don't apply to the problem at hand. Simply, the function will count how many authors are labled as 'first'. Once all authors of a record have been parsed, we go to the `return` statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69fe0c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_checker(authorList):\n",
    "    counter = 0 \n",
    "    try: \n",
    "        for author in authorList:\n",
    "                if 'name' in author.keys():\n",
    "                    if len(authorList) == 1:\n",
    "                        counter +=1\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    if author['sequence'] == 'first':\n",
    "                        counter +=1\n",
    "                    else:\n",
    "                        continue\n",
    "        if counter == 0:\n",
    "            return 1 #no first author\n",
    "        elif len(authorList) > 1:\n",
    "            if counter > 1:\n",
    "                return 1 #multiple first authors\n",
    "            else:\n",
    "                return 0\n",
    "        else:\n",
    "            return 0 #no issue\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fa31149-ad1f-451a-8350-57845288b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_checker2(authorList: list[dict[str]]| None) -> int | None:\n",
    "    \"\"\"Function to check the value of the 'sequence' key for each\n",
    "    author within a record.\n",
    "\n",
    "    Args:\n",
    "        authorList (list[dict[str]] | None): The nested list of authors for each record.\n",
    "\n",
    "    Returns:\n",
    "        int | None: Returns a binary encoding (0, 1) depending on the (non-)existence of an issue.\n",
    "        Returns None if the record is incomplete such that a determination cannot be made.\n",
    "    \"\"\"\n",
    "    counter = 0 \n",
    "    try: \n",
    "        for author in authorList:\n",
    "                #if 'name' in author.keys():\n",
    "                    #if len(authorList) == 1:\n",
    "                        #counter +=1\n",
    "                    #else:\n",
    "                        #continue\n",
    "                #else:\n",
    "                if author['sequence'] == 'first':\n",
    "                    counter +=1\n",
    "                else:\n",
    "                    continue\n",
    "        if counter == 0:\n",
    "            return 0 # There is no first author.\n",
    "        elif counter == 1:\n",
    "            if len(authorList) == 1:\n",
    "                return 1 # There's only one author and this author is also tagged as first author\n",
    "            else:\n",
    "                return 2 # There are multiple authors and only one of them is labeled as first author\n",
    "        else:\n",
    "            if counter == len(authorList):\n",
    "                return 3 # All authors are labeled as first authors\n",
    "            else: \n",
    "                return 4 # More than one and less than all authors are labeled as first authors\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b83e25fc-759f-4650-b76a-6da72b08d0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Author Sequence Encoding'] = df.authors.map(lambda x: sequence_checker2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b92cefa7-ddd2-4cfa-bb7e-931ce35705a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_author_none = df.loc[df['Author Sequence Encoding'] == 0]\n",
    "first_author_only = df.loc[df['Author Sequence Encoding'] == 1]\n",
    "first_author_oneamong = df.loc[df['Author Sequence Encoding'] == 2]\n",
    "first_author_all = df.loc[df['Author Sequence Encoding'] == 3]\n",
    "first_author_some = df.loc[df['Author Sequence Encoding'] == 4]\n",
    "# Note that this deviates from our usual approach of encoding quality issues binary in 0/1. \n",
    "# But these cases are so different that I wanted to have more details here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ba01038-fda6-4cde-8d9f-1db15437ab5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28% of all articles have no first author.\n",
      "26.86% of all articles have one author and that author is the first author.\n",
      "60.60% of all articles have multiple authors, but only one first author.\n",
      "1.26% of all articles have all authors tagged as first authors.\n",
      "1.25% of all articles have more than one first author, but not all authors are first authors.\n"
     ]
    }
   ],
   "source": [
    "first_author_none_rate = len(first_author_none)/len(df)*100\n",
    "first_author_only_rate = len(first_author_only)/len(df)*100\n",
    "first_author_oneamong_rate = len(first_author_oneamong)/len(df)*100\n",
    "first_author_all_rate = len(first_author_all)/len(df)*100\n",
    "first_author_some_rate = len(first_author_some)/len(df)*100\n",
    "\n",
    "print(\"{:0.2f}% of all articles have no first author.\".format(first_author_none_rate))\n",
    "print(\"{:0.2f}% of all articles have one author and that author is the first author.\".format(first_author_only_rate))\n",
    "print(\"{:0.2f}% of all articles have multiple authors, but only one first author.\".format(first_author_oneamong_rate))\n",
    "print(\"{:0.2f}% of all articles have all authors tagged as first authors.\".format(first_author_all_rate))\n",
    "print(\"{:0.2f}% of all articles have more than one first author, but not all authors are first authors.\".format(first_author_some_rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bd3c6e8-97f8-47d7-99b7-5b4aa035fdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31% of all articles that actually have authors have no first author.\n",
      "29.76% of all articles that actually have authors have one author and that author is the first author.\n",
      "67.15% of all articles that actually have authors have multiple authors, but only one first author.\n",
      "1.39% of all articles that actually have authors have all authors tagged as first authors.\n",
      "1.39% of all articles that actually have authors have more than one first author, but not all authors are first authors.\n"
     ]
    }
   ],
   "source": [
    "first_author_none_rate_only_authored_articles = len(first_author_none)/df.authors.notnull().sum()*100\n",
    "first_author_only_rate_only_authored_articles = len(first_author_only)/df.authors.notnull().sum()*100\n",
    "first_author_oneamong_rate_only_authored_articles = len(first_author_oneamong)/df.authors.notnull().sum()*100\n",
    "first_author_all_rate_only_authored_articles = len(first_author_all)/df.authors.notnull().sum()*100\n",
    "first_author_some_rate_only_authored_articles = len(first_author_some)/df.authors.notnull().sum()*100\n",
    "\n",
    "print(\"{:0.2f}% of all articles that actually have authors have no first author.\".format(first_author_none_rate_only_authored_articles))\n",
    "print(\"{:0.2f}% of all articles that actually have authors have one author and that author is the first author.\".format(first_author_only_rate_only_authored_articles))\n",
    "print(\"{:0.2f}% of all articles that actually have authors have multiple authors, but only one first author.\".format(first_author_oneamong_rate_only_authored_articles))\n",
    "print(\"{:0.2f}% of all articles that actually have authors have all authors tagged as first authors.\".format(first_author_all_rate_only_authored_articles))\n",
    "print(\"{:0.2f}% of all articles that actually have authors have more than one first author, but not all authors are first authors.\".format(first_author_some_rate_only_authored_articles))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f802002a",
   "metadata": {},
   "source": [
    "## Author Initials\n",
    "This function will utilize regular expressions for detecting the use of initials. Specifically, we are looking for when initials are used in totality, that is to say a record with \"Marianne E.\" will not be flagged, whereas a record with \"D.\" will.\n",
    "\n",
    "We look in both the 'given' and the 'family' sub-fields as this use of initials has been found in both sub-fields previously. \n",
    "\n",
    "The flow of the function operates similarly to the `sequence_checker`, we filter out records with `null` authors in the first `try` statement, followed by iteration through the author list, then another `try` statement where we filter out institutions as authors.\n",
    "\n",
    "The regular expressions can be broken into two conditions: `^(?:[A-Z]\\W{,3}\\s?){,3}` and `(?:[^\\W\\d_.]\\W){1,2}\\B` which are seperated by `|`. This is because each of those expressions are looking for initials, the former is looking in ASCII characters, whereas the latter s looking for the pattern in non-Latin characters.\n",
    "\n",
    "`if detector != None or len(author['given']) == 1` ensures that all initialized names are caught and then returned with the appropriate label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9459997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_initials_checker(authorList: list[dict[str]] | None) -> int | None:\n",
    "    \"\"\"Function that evaluates author names to determine the use of initials.\n",
    "\n",
    "    Args:\n",
    "        authorList (list[dict[str]] | None): The nested list of authors for each record.\n",
    "\n",
    "    Returns:\n",
    "        int | None: Returns a binary encoding (0, 1) depending on the (non-)existence of an issue.\n",
    "        Returns None if the record is incomplete such that a determination cannot be made.\n",
    "    \"\"\"\n",
    "    try: \n",
    "        for author in authorList: \n",
    "            try: \n",
    "                detector = re.search(r\"^(?:[A-Z]\\W{,3}\\s?){1,3}$\", author['given_name']) \n",
    "                if detector or len(author['given_name']) == 1:\n",
    "                    return 1 \n",
    "                else:\n",
    "                    family_detector = re.search(r\"^(?:[A-Z]\\W{,3}\\s?){1,3}$\", author['surname']) \n",
    "                    if family_detector or len(author['surname']) == 1:\n",
    "                        return 1 \n",
    "                    else:\n",
    "                        pass\n",
    "            except:\n",
    "                pass\n",
    "                        \n",
    "    except:\n",
    "        return None\n",
    "    return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "942bb710",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Author Initials'] = df.authors.map(lambda x: author_initials_checker(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64e7e290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.12 percent of the article records contain at least one author with only initials given\n",
      "25.62 percent of the article records that actually have authors contain at least one author with only initials given\n",
      "Number of records:  122531\n"
     ]
    }
   ],
   "source": [
    "records_with_initials = df.loc[df['Author Initials'] == 1]\n",
    "prevalence_author_initials_only_authored_articles = ((len(records_with_initials))/(df.authors.notnull().sum())) * 100\n",
    "prevalence_author_initials_all_articles = len(records_with_initials)/len(df) * 100\n",
    "#prevalence_author_initials # percentage of records with this specific issue\n",
    "print(\"{:0.2f} percent of the article records contain at least one author with only initials given\".format(prevalence_author_initials_all_articles))\n",
    "print(\"{:0.2f} percent of the article records that actually have authors contain at least one author with only initials given\".format(prevalence_author_initials_only_authored_articles))\n",
    "print(\"Number of records: \",len(records_with_initials))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f28c121",
   "metadata": {},
   "source": [
    "## Institutions as Authors RE-CHECK OUTCOMES HERE\n",
    "\n",
    "**Need to adjust all author labelling functions to account for different author info schema. Inclusion of institutional authors has altered the schema and thus affecting the numbers.**\n",
    "\n",
    "This function will address instances in which institutions are recorded as authors.\n",
    "\n",
    "`try:` will filter out records with `null` authors. Then we have the `institutions_present` list that looks for the telltale sign of an institution, the 'name' sub-field. \n",
    "\n",
    "If the list is populated with any authors, then the appropriate label signalling an institution will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6144469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def institution_as_author(authorList: list[dict[str]] | None) -> int | None:\n",
    "    \"\"\"Function to determine if an institution is listed as an author\n",
    "    within a record.\n",
    "\n",
    "    Args:\n",
    "        authorList (list[dict[str]] | None): The nested list of authors for each record.\n",
    "\n",
    "    Returns:\n",
    "        int | None: Returns a binary encoding (0, 1) depending on the (non-)existence of an issue.\n",
    "        Returns None if the record is incomplete such that a determination cannot be made.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        institutions_present = [author for author in authorList if author['name'] != None]\n",
    "        if len(institutions_present) > 0:\n",
    "            return 1 #institution as author\n",
    "        else:\n",
    "            return 0 #no issue\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83a3da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Institutions as Authors'] = df.authors.map(lambda x: institution_as_author(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e780196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.83 percent of the article records list at least one institution as an author\n",
      "2.02 percent of the article records that actually have authors list at least one institution as an author\n",
      "Number of records:  9684\n"
     ]
    }
   ],
   "source": [
    "records_with_AuIns = df.loc[df['Institutions as Authors'] == 1]\n",
    "prevalence_AuIns_only_authored_articles = ((len(records_with_AuIns))/(df.authors.notnull().sum())) * 100\n",
    "prevalence_AuIns_all_articles = ((len(records_with_AuIns))/len(df)) * 100\n",
    "#prevalence_AuIns #percentage of records with this specific issue\n",
    "print(\"{:0.2f} percent of the article records list at least one institution as an author\".format(prevalence_AuIns_all_articles))\n",
    "print(\"{:0.2f} percent of the article records that actually have authors list at least one institution as an author\".format(prevalence_AuIns_only_authored_articles))\n",
    "print(\"Number of records: \",len(records_with_AuIns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c169e7",
   "metadata": {},
   "source": [
    "## Affiliation Missing\n",
    "\n",
    "This function will check if there is any data present within the Author `\"Affiliation\"` subfield.\n",
    "\n",
    "We start by creating a variable to operate as a indicator to the presence of an affiliation. We then iterate through each author within a given record.\n",
    "\n",
    "If an affiliation is present, we change the indicator to be `False`. After checking the authors, we assign `1` to records that are missing affiliations or `0` if there is no issue present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8130803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def affiliations_missing(authorList: list[dict[str]] | None) -> int | None:\n",
    "    \"\"\"Function to determine the presence of affiliations for authors within a record.\n",
    "\n",
    "    Args:\n",
    "        authorList (list[dict[str]] | None): The nested list of authors for each record.\n",
    "\n",
    "    Returns:\n",
    "        int | None: Returns a binary encoding (0, 1) depending on the (non-)existence of an issue.\n",
    "        Returns None if the record is incomplete such that a determination cannot be made.\n",
    "    \"\"\"\n",
    "    no_affil = True\n",
    "    try:\n",
    "        if len(authorList) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            for author in authorList:\n",
    "                if author['affiliation'] is None:\n",
    "                    continue\n",
    "                else:\n",
    "                    no_affil = False\n",
    "        if no_affil:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "368cffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Affiliation Missing'] = df.authors.map(lambda x: affiliations_missing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78049ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.37 percent of the article records miss the affiliation for every author.\n"
     ]
    }
   ],
   "source": [
    "records_missing_affil = df.loc[df['Affiliation Missing'] == 1]\n",
    "prevalence_miss_affil = ((len(records_missing_affil))/(df.authors.notnull().sum())) * 100\n",
    "#prevalence_miss_affil\n",
    "print(\"{:0.2f} percent of the article records miss the affiliation for every author.\".format(prevalence_miss_affil))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4bf85e",
   "metadata": {},
   "source": [
    "## Checking for Honorifics in Author Names\n",
    "\n",
    "This function utilizes a set list of honorifics found, in Phase 1, to be used within the Author `\"Given\"` and `\"Family\"` subfields.\n",
    "\n",
    "After establishing our list, we then iterate through each Author of every record, putting their names into a lowercase format.\n",
    "\n",
    "We then check the given and family names for the use of the listed titles. Return `1` if an honorific is present. Return `0` if none are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acccf66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def honorific_checker(authorList: list[dict[str]] | None) -> int | None:\n",
    "    \"\"\"Function for detecting the use of honorifics within author names of a given record.\n",
    "\n",
    "    Args:\n",
    "        authorList (list[dict[str]] | None): The nested list of authors for each record\n",
    "\n",
    "    Returns:\n",
    "        int | None: Returns a binary encoding (0, 1) depending on the (non-)existence of an issue.\n",
    "        Returns None if the record is incomplete such that a determination cannot be made.\n",
    "    \"\"\"\n",
    "    titles_list = set(['dr.', 'prof', 'prof.', 'professor', 'doctor', 'dr', 'ingeniero'])\n",
    "    try:\n",
    "        for author in authorList:\n",
    "            lowercase_given = author['given_name'].lower()\n",
    "            lowercase_family = author['surname'].lower()\n",
    "            if any(word in titles_list for word in lowercase_given.split()):\n",
    "                return 1\n",
    "            elif any(word in titles_list for word in lowercase_family.split()):\n",
    "                return 1\n",
    "            else: \n",
    "                continue\n",
    "        return 0\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f755a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Author Use of Honorific'] = df.authors.map(lambda x: honorific_checker(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13b4c0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least 0.09 percent of the article records contain honorifics within the author names .\n",
      "At least 0.08 percent of the article records that actually have authors contain honorifics within the author names .\n",
      "Number of records:  442\n"
     ]
    }
   ],
   "source": [
    "records_with_honorific = df.loc[df['Author Use of Honorific'] == 1]\n",
    "prevalence_honorific_all_articles = ((len(records_with_honorific))/df.authors.notnull().sum()) * 100\n",
    "prevalence_honorific_only_authored_articles = ((len(records_with_honorific))/len(df)) * 100\n",
    "#prevalence_honorific\n",
    "print(\"At least {:0.2f} percent of the article records contain honorifics within the author names .\".format(prevalence_honorific_all_articles))\n",
    "print(\"At least {:0.2f} percent of the article records that actually have authors contain honorifics within the author names .\".format(prevalence_honorific_only_authored_articles))\n",
    "print(\"Number of records: \",len(records_with_honorific))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d20b3e",
   "metadata": {},
   "source": [
    "## Uppercase Author Names\n",
    "\n",
    "With this function we will check each Author's `\"Given\"` and `\"Family\"` name subfields to see if the input is in all upercase letters.\n",
    "\n",
    "We start iterating through the author list and filter out records wherein the number of characters in a `\"Given\"` name is `1`. These are likely to be initials and as such are covered by another dimension of issue detection. We then use the regular expression `(?:^[A-Z]+)$` to return matches when an Author's name is in all uppercase letters. \n",
    "\n",
    "If a match is found we return `1` to signifiy the existence of an issue. If no match is returned, we repeat the process using the author's `\"Family\"` name. If no match is found for the `\"Family\"` name, then we proceed with the next author within the record until all authors have been checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ad92850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uppercase_name(authorList: list[dict[str]] | None) -> int | None:\n",
    "    \"\"\"Function for determining the presence of a name using exclusively capital letters.\n",
    "\n",
    "    Args:\n",
    "        authorList (list[dict[str]] | None): The nested list of authors for each record.\n",
    "\n",
    "    Returns:\n",
    "        int | None: Returns a binary encoding (0, 1) depending on the (non-)existence of an issue.\n",
    "        Returns None if the record is incomplete such that a determination cannot be made.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for author in authorList:\n",
    "            if len(author['given_name']) == 1:\n",
    "                continue\n",
    "            else:\n",
    "                if re.match(r'(?:^[A-Z]+)$', author['given_name']):\n",
    "                    return 1\n",
    "                else:\n",
    "                    if len(author['surname']) == 1:\n",
    "                        continue\n",
    "                    else:\n",
    "                        if re.match(r'(?:^[A-Z]+)$', author['surname']):\n",
    "                            return 1\n",
    "                        else:\n",
    "                            continue\n",
    "        return 0\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d324791",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Author Name in All Caps'] = df.authors.map(lambda x: uppercase_name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cced143d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.18 percent of the article records contain author names in all uppercase letters.\n",
      "5.74 percent of the article records that actually have authors contain author names in all uppercase letters.\n",
      "Number of records:  27457\n"
     ]
    }
   ],
   "source": [
    "records_uppercase = df.loc[df['Author Name in All Caps'] == 1]\n",
    "prevalence_uppercase_only_authored_articles = ((len(records_uppercase))/df.authors.notnull().sum()) * 100\n",
    "prevalence_uppercase_all_articles = ((len(records_uppercase))/len(df)) * 100\n",
    "#prevalence_uppercase\n",
    "print(\"{:0.2f} percent of the article records contain author names in all uppercase letters.\".format(prevalence_uppercase_all_articles))\n",
    "print(\"{:0.2f} percent of the article records that actually have authors contain author names in all uppercase letters.\".format(prevalence_uppercase_only_authored_articles))\n",
    "print(\"Number of records: \",len(records_uppercase))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f518d78",
   "metadata": {},
   "source": [
    "## Non-Latin Characters\n",
    "\n",
    "This function detects the use of non-latin character sets. Particularly we are interested in practices of romanization and when it occurs: which journals, are the *language* fields present and accurate, and so on. \n",
    "\n",
    "First, we have to identify which records are using non-latin characters.\n",
    "\n",
    "This is split into two different functions. The first utilizes a regular expression `(?:[^ı́\\x00-\\xff])` to detect any characters not in ISO-8859-1 (or Latin-1) (See note).\n",
    "\n",
    "The second then utlizes the first function to then check each author within a given record.\n",
    "\n",
    "Note: This expression is providing a few too many false positives for my liking. I'm currently working on a better expression or a different solution entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4fcdca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isLatinChar(authorName: str) -> bool:\n",
    "    \"\"\"Helper function for evaluating the presence of Latin characters.\n",
    "\n",
    "    Args:\n",
    "        authorName (str): An Author's name.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if non-Latin characters are used. False if exclusively Latin characters are used.\n",
    "    \"\"\"\n",
    "    regexp = re.compile(r'(?:[^ı́\\x00-\\xff])')\n",
    "    if regexp.search(authorName):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def latin_script_checker(authorList: list[dict[str]] | None) -> int | None:\n",
    "    \"\"\"Function for evaluating author names within each record for the presence\n",
    "    of non-Latin characters.\n",
    "\n",
    "    Args:\n",
    "        authorList (list[dict[str]] | None): The nested list of authors for each record.\n",
    "\n",
    "    Returns:\n",
    "        int | None: Returns a binary encoding (0, 1) depending on the (non-)existence of an issue.\n",
    "        Returns None if the record is incomplete such that a determination cannot be made.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        latin_scripts = [author for author in authorList if isLatinChar(author['given_name'])]\n",
    "        if len(latin_scripts) > 0:\n",
    "            return 1 # non-latin script found\n",
    "        else:\n",
    "            return 0 # no issue\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1f6ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Non-ASCII Characters'] = df.authors.map(lambda x: latin_script_checker(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df746dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.73 percent of the article records contain author (given) names in non-Latin letters.\n"
     ]
    }
   ],
   "source": [
    "records_with_non_latin = df.loc[df['Non-ASCII Characters'] == 1]\n",
    "prevalence_NonLatin = ((len(records_with_non_latin))/(df.authors.notnull().sum())) * 100\n",
    "#prevalence_NonLatin #percentage of records with this specific issue\n",
    "print(\"{:0.2f} percent of the article records contain author (given) names in non-Latin letters.\".format(prevalence_NonLatin))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03105fd4",
   "metadata": {},
   "source": [
    "## Abstract Multi-lingualism Detection\n",
    "This function will detect the use of more than one language within the *abstract* field. As mentioned before, we're interested in how people pracitice recording metadata as it pertains to language.\n",
    "\n",
    "Here we have a list of language ISO 639-1 codes. While it is not exhaustive (there are 183 offically assigned codes, and only 94 are present in this list), it does include many of the macrolanguages for which many other languages fall within.\n",
    "\n",
    "We pass this list to `langid` to ensure a higher confidence intervals in it's identification, i.e. an abstract might be in Malay (ms) but the identifier might return 'ms' and 'id' (Indonesian) with lower confidence intervals for each. As Malay is the macrolanguage that covers Indonesian, we will keep 'ms' but not 'id'.\n",
    "\n",
    "The first `try:` block filters for records without abstracts present, then we tokenize the abstracts by sentence.\n",
    "\n",
    "Next we pick out the first sentence and the second to last sentence of each abstract. The reason for picking out the second to last sentence is because most occurences of multi-lingual abstracts are such that the abstract is first written in one language, and then a second time in another. The reason for not picking the last sentence is because it is not uncommon for footnotes or citations to be present at the end of the abstracts in these metadata records. The presence of these at the end of an abstract section make language detection problematic as the syntactical structure can be odd and leads to an incorrect detection.\n",
    "\n",
    "We then classify both sentences, followed by an evaluation of the confidence intervals. If the confidence interval is especially low, it is omitted.\n",
    "\n",
    "We then check to see if there is more than one language present in the dictionary with `len(set(lang_dict.keys()))`, if so the record is returned with a **1**, indicating and error. Otherwise it is returned with a **0**.\n",
    "\n",
    "If this is the first time running this notebook, you may need to uncomment the top two lines of the cell:\n",
    "\n",
    "`import nltk`\n",
    "\n",
    "`nltk.download('punkt')`\n",
    "\n",
    "This is necessary for `sent_tokenize` to work as intended.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc50cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "identifier = LanguageIdentifier.from_pickled_model(MODEL_FILE, norm_probs = True)\n",
    "lang_list = ['af', 'am', 'ar', 'as', 'az', 'be', 'bg', 'bn', 'br', \n",
    "             'bs', 'ca', 'cs', 'cy', 'da', 'de', 'dz', 'el', 'en', 'eo', \n",
    "             'es', 'et', 'eu', 'fa', 'fi', 'fo', 'fr', 'ga', 'gl', 'gu', \n",
    "             'he', 'hi', 'hr', 'ht', 'hu', 'hy', 'is', 'it', 'ja', 'jv', \n",
    "             'ka', 'kk', 'km', 'kn', 'ko', 'ku', 'ky', 'la', 'lb', 'lo', \n",
    "             'lt', 'lv', 'mg', 'mk', 'ml', 'mn', 'mr', 'ms', 'mt', 'ne', \n",
    "             'nl', 'no', 'oc', 'or', 'pa', 'pl', 'ps', 'pt', 'qu', 'ro', \n",
    "             'ru', 'rw', 'se', 'si', 'sk', 'sl', 'sq', 'sr', 'sv', 'sw', \n",
    "             'ta', 'te', 'th', 'tl', 'tr', 'ug', 'uk', 'ur', 'vi', 'vo', \n",
    "             'wa', 'xh', 'zh', 'zu']\n",
    "identifier.set_languages(langs=lang_list)\n",
    "def lang_checker(abstracts: list[str] | None) -> int | None:\n",
    "    \"\"\"Function for checking for multilingual abstracts by analysing the language\n",
    "    used at the beginning and end of each abstract within a record.\n",
    "\n",
    "    Args:\n",
    "        abstracts (list[str] | None): List of abstracts.\n",
    "\n",
    "    Returns:\n",
    "        int | None: Returns a binary encoding (0, 1) depending on the (non-)existence of an issue.\n",
    "        Returns None if the record is incomplete such that a determination cannot be made.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for abstract in abstracts:\n",
    "            # Tokenizing abstracts\n",
    "            tokenized = sent_tokenize(abstract)\n",
    "            startAndFinish = [tokenized[0], tokenized[-1]]\n",
    "            # Detecting languages present\n",
    "            lang = [identifier.classify(lang) for lang in startAndFinish]\n",
    "            # Filter low confidence results\n",
    "            lang_dict = {key:value for (key,value) in lang if value > .95}\n",
    "            # Labeling specific issues found in record\n",
    "            if len(set(lang_dict.keys())) > 1:\n",
    "                return 1 #Multiple languages detected\n",
    "    except:\n",
    "        return None #No abstract\n",
    "    return 0 #No issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c771c541",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Multilingual Abstract']  = df.abstracts.map(lambda x: lang_checker(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a0dd8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40 percent of the article records contain abstracts that contain more than one language.\n",
      "1.61 percent of the article records with abstract contain abstracts that contain more than one language.\n",
      "Number of records:  2099\n"
     ]
    }
   ],
   "source": [
    "records_with_MultiLang = df.loc[(df['Multilingual Abstract'] == 1)]\n",
    "prevalence_MultiLang_only_articles_with_abstract = ((len(records_with_MultiLang))/(df.abstracts.notnull().sum())) * 100\n",
    "prevalence_MultiLang_all_articles = ((len(records_with_MultiLang))/len(df)) * 100\n",
    "#prevalence_MultiLang #returning a percent of the total number of records with this particular issue\n",
    "print(\"{:0.2f} percent of the article records contain abstracts that contain more than one language.\".format(prevalence_MultiLang_all_articles))\n",
    "print(\"{:0.2f} percent of the article records with abstract contain abstracts that contain more than one language.\".format(prevalence_MultiLang_only_articles_with_abstract))\n",
    "print(\"Number of records: \",len(records_with_MultiLang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14820399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in count of abstracts. Count of different abstracts in different languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bfcf19-66bf-4939-9565-48948a97e66e",
   "metadata": {},
   "source": [
    "### Explore the multilingual abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9cf7e3ae-1239-4793-9ee1-2b00c94fede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#records_with_MultiLang['DOI'].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788b2f65-9d64-4a61-b117-3c6121132103",
   "metadata": {},
   "source": [
    "## Abstract Language Checking\n",
    "This function will check the language of the abstract against the stated language of the record.\n",
    "\n",
    "It is a relatively striaghtforward function: `try:` filters out records without a *abstract*, then classifies the language, and finally checks to see if the returned code matches what is record in the language field.\n",
    "\n",
    "We use `df.apply` instead of `df.column.map` because of the need to check multiple fields within a record as opposed to being contained within a specific field.\n",
    "\n",
    "Here, it should be mentioned, there is some abiguity. The *language* field is not clearly defined (is it the language of the Item, Container, or the record). The prevelance of this issue (seen below) reflects the lack of clarity in what this field is meant to represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ded6a28-563f-4de6-b433-f01e7e7ae7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_journal_language(record: pd.Series) -> int | None:\n",
    "    \"\"\"Function to determine if the stated language of an article\n",
    "    matches the stated language of the journal within a given record.\n",
    "\n",
    "    Args:\n",
    "        record (pd.Series): A metadata record from the dataframe.\n",
    "\n",
    "    Returns:\n",
    "        int | None: Returns a binary encoding (0, 1) depending on the (non-)existence of an issue.\n",
    "        Returns None if the record is incomplete such that a determination cannot be made.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if record['article_lang'] == record['journal_lang']:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def abstract_lang_checker(record: pd.Series) -> int | None:\n",
    "    \"\"\"Function to determine if the stated language of an abstract\n",
    "    matches the stated language of the journal within a given record.\n",
    "\n",
    "    Args:\n",
    "        record (pd.Series): A metadata record from the dataframe.\n",
    "\n",
    "    Returns:\n",
    "        int | None: Returns a binary encoding (0, 1) depending on the (non-)existence of an issue.\n",
    "        Returns None if the record is incomplete such that a determination cannot be made.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for i in record['abstracts']:\n",
    "            if i:\n",
    "                lang = identifier.classify(i)\n",
    "                if lang[1] > .99:\n",
    "                    if lang[0] == record['journal_lang']:\n",
    "                        return 0\n",
    "                    else:\n",
    "                        if record['journal_lang'] is None:\n",
    "                            return None\n",
    "                        else:\n",
    "                            return 1\n",
    "                else:\n",
    "                    return None\n",
    "            else:\n",
    "                return None\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb09835c-da9a-4eb9-819f-b8b7ef00f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Abstract Language Match'] = df.apply(abstract_lang_checker, axis=1)\n",
    "df['Article-Journal Language Match'] = df.apply(article_journal_language, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "016fb80c-7cbb-424c-8da0-abcd815d2dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.24 percent of the article records with abstracts and language information have a mismatch between the given language and the detected language of the article abstract.\n",
      "0.58 percent of all article records have a mismatch between the given language and the detected language of the article abstract.\n"
     ]
    }
   ],
   "source": [
    "records_with_AbstractLang = df.loc[(df['Abstract Language Match'] == 1)] #creating a df with only the records with these errors\n",
    "prevalence_AbstractLang_only_articles_with_abstract = ((len(records_with_AbstractLang))/len(df.loc[(df.abstracts.notnull()) & (df.article_lang.notnull())])) * 100\n",
    "prevalence_AbstractLang_all_articles = ((len(records_with_AbstractLang))/len(df)) * 100\n",
    "#prevalence_AbstractLang #returning a percent of the total number of records with this particular issue\n",
    "print(\"{:0.2f} percent of the article records with abstracts and language information have a mismatch between the given language and the detected language of the article abstract.\".format(prevalence_AbstractLang_only_articles_with_abstract))\n",
    "print(\"{:0.2f} percent of all article records have a mismatch between the given language and the detected language of the article abstract.\".format(prevalence_AbstractLang_all_articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0727535b-a55a-4fee-8e64-8418fb3b4be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#records_with_AbstractLang['DOI'].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e54b1e",
   "metadata": {},
   "source": [
    "## Title Language Checking\n",
    "This function will check the language of the title against the stated language of the record.\n",
    "\n",
    "It is a relatively striaghtforward function: `try:` filters out records without a *title*, then classifies the language, and finally checks to see if the returned code matches what is record in the language field.\n",
    "\n",
    "We use `df.apply` instead of `df.column.map` because of the need to check multiple fields within a record as opposed to being contained within a specific field.\n",
    "\n",
    "Here, it should be mentioned, there is some abiguity. The *language* field is not clearly defined (is it the language of the Item, Container, or the record). The prevelance of this issue (seen below) reflects the lack of clarity in what this field is meant to represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3bf0d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_lang_checker(record: pd.Series) -> int | None:\n",
    "    \"\"\"Function to determine if the detected language of the title matches\n",
    "    the stated language of the journal within a given record.\n",
    "\n",
    "    Args:\n",
    "        record (pd.Series): A metadata record from the dataframe.\n",
    "\n",
    "    Returns:\n",
    "        int | None: Returns a binary encoding (0, 1) depending on the (non-)existence of an issue.\n",
    "        Returns None if the record is incomplete such that a determination cannot be made.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if record['article_title']:\n",
    "            for i in record['article_title']:\n",
    "                lang = identifier.classify(i)\n",
    "                if lang[1] > .99:\n",
    "                    if lang[0] == record['journal_lang']:\n",
    "                        return 0\n",
    "                    else:\n",
    "                        if str(record['journal_lang']).lower() == 'nan':\n",
    "                            return None\n",
    "                        else:\n",
    "                            return 1\n",
    "                else:\n",
    "                    return None\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4da95282",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title Language Match'] = df.apply(title_lang_checker, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b04787a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.09 percent of the article records with titles and language information have a mismatch between the given language and the detected language of the article title.\n",
      "18.17 percent of all article records have a mismatch between the given language and the detected language of the article title.\n"
     ]
    }
   ],
   "source": [
    "records_with_TitleLang = df.loc[(df['Title Language Match'] == 1)] #creating a df with only the records with these errors\n",
    "prevalence_TitleLang_only_articles_with_title = ((len(records_with_TitleLang))/len(df.loc[(df.article_title.notnull()) & (df.journal_lang.notnull())])) * 100\n",
    "prevalence_TitleLang_all_articles = ((len(records_with_TitleLang))/len(df)) * 100\n",
    "#prevalence_TitleLang #returning a percent of the total number of records with this particular issue\n",
    "print(\"{:0.2f} percent of the article records with titles and language information have a mismatch between the given language and the detected language of the article title.\".format(prevalence_TitleLang_only_articles_with_title))\n",
    "print(\"{:0.2f} percent of all article records have a mismatch between the given language and the detected language of the article title.\".format(prevalence_TitleLang_all_articles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea01fe6e",
   "metadata": {},
   "source": [
    "## Total Errors\n",
    "Lastly, we'll add up all of the errors for each record and store them number in *'total_errors'* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "174bef3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labled Columns\n",
    "column_list = ['Author Missing', 'Article Language Missing', 'Journal Language Missing',\n",
    "                'Abstract Missing', 'Article Title Missing', 'Journal Title Missing',\n",
    "                'Institutions as Authors', 'Affiliation Missing', 'Author Use of Honorific',\n",
    "                'Author Name in All Caps', 'Non-ASCII Characters', 'Multilingual Abstract',\n",
    "                'Abstract Language Match', 'Article-Journal Language Match', 'Title Language Match'\n",
    "                ]\n",
    "df['Total Errors'] = df[column_list].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "10a77453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_langs</th>\n",
       "      <th>abstracts</th>\n",
       "      <th>article_lang</th>\n",
       "      <th>article_title</th>\n",
       "      <th>authors</th>\n",
       "      <th>doi</th>\n",
       "      <th>journal_lang</th>\n",
       "      <th>journal_title</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>Author Missing</th>\n",
       "      <th>...</th>\n",
       "      <th>Institutions as Authors</th>\n",
       "      <th>Affiliation Missing</th>\n",
       "      <th>Author Use of Honorific</th>\n",
       "      <th>Author Name in All Caps</th>\n",
       "      <th>Non-ASCII Characters</th>\n",
       "      <th>Multilingual Abstract</th>\n",
       "      <th>Abstract Language Match</th>\n",
       "      <th>Article-Journal Language Match</th>\n",
       "      <th>Title Language Match</th>\n",
       "      <th>Total Errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Revolving Boot Crimping Machine]</td>\n",
       "      <td>None</td>\n",
       "      <td>10.1038/scientificamerican04281849-249k</td>\n",
       "      <td>None</td>\n",
       "      <td>Scientific American</td>\n",
       "      <td>Springer Science and Business Media LLC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Development of Desktop CNC Lathe with Pipe Fr...</td>\n",
       "      <td>[{'affiliation': None, 'given_name': 'Naohiko'...</td>\n",
       "      <td>10.2493/jjspe.85.189</td>\n",
       "      <td>en</td>\n",
       "      <td>Journal of the Japan Society for Precision Eng...</td>\n",
       "      <td>Japan Society for Precision Engineering</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[0547 Predicting Response to Oral Appliance Th...</td>\n",
       "      <td>[{'affiliation': 'Zephyr Sleep Technologies, C...</td>\n",
       "      <td>10.1093/sleep/zsy061.546</td>\n",
       "      <td>en</td>\n",
       "      <td>Sleep</td>\n",
       "      <td>Oxford University Press (OUP)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Anomalous absorption of hydrogen peroxide (H2...</td>\n",
       "      <td>[{'affiliation': None, 'given_name': 'Mohit K....</td>\n",
       "      <td>10.1016/j.jqsrt.2020.107085</td>\n",
       "      <td>en</td>\n",
       "      <td>Journal of Quantitative Spectroscopy and Radia...</td>\n",
       "      <td>Elsevier BV</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Cultura emprendedora de los estudiantes de Ma...</td>\n",
       "      <td>[{'affiliation': None, 'given_name': None, 'na...</td>\n",
       "      <td>10.24265/iggp.2020.v7n1.09</td>\n",
       "      <td>None</td>\n",
       "      <td>Revista en Gobierno y Gestión Pública</td>\n",
       "      <td>Universidad de San Martin de Porres</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_langs abstracts article_lang  \\\n",
       "0           None      None         None   \n",
       "1           None      None         None   \n",
       "2           None      None         None   \n",
       "3           None      None         None   \n",
       "4           None      None         None   \n",
       "\n",
       "                                       article_title  \\\n",
       "0                  [Revolving Boot Crimping Machine]   \n",
       "1  [Development of Desktop CNC Lathe with Pipe Fr...   \n",
       "2  [0547 Predicting Response to Oral Appliance Th...   \n",
       "3  [Anomalous absorption of hydrogen peroxide (H2...   \n",
       "4  [Cultura emprendedora de los estudiantes de Ma...   \n",
       "\n",
       "                                             authors  \\\n",
       "0                                               None   \n",
       "1  [{'affiliation': None, 'given_name': 'Naohiko'...   \n",
       "2  [{'affiliation': 'Zephyr Sleep Technologies, C...   \n",
       "3  [{'affiliation': None, 'given_name': 'Mohit K....   \n",
       "4  [{'affiliation': None, 'given_name': None, 'na...   \n",
       "\n",
       "                                       doi journal_lang  \\\n",
       "0  10.1038/scientificamerican04281849-249k         None   \n",
       "1                     10.2493/jjspe.85.189           en   \n",
       "2                 10.1093/sleep/zsy061.546           en   \n",
       "3              10.1016/j.jqsrt.2020.107085           en   \n",
       "4               10.24265/iggp.2020.v7n1.09         None   \n",
       "\n",
       "                                       journal_title  \\\n",
       "0                                Scientific American   \n",
       "1  Journal of the Japan Society for Precision Eng...   \n",
       "2                                              Sleep   \n",
       "3  Journal of Quantitative Spectroscopy and Radia...   \n",
       "4              Revista en Gobierno y Gestión Pública   \n",
       "\n",
       "                            publisher_name  Author Missing  ...  \\\n",
       "0  Springer Science and Business Media LLC             1.0  ...   \n",
       "1  Japan Society for Precision Engineering             0.0  ...   \n",
       "2            Oxford University Press (OUP)             0.0  ...   \n",
       "3                              Elsevier BV             0.0  ...   \n",
       "4      Universidad de San Martin de Porres             0.0  ...   \n",
       "\n",
       "   Institutions as Authors  Affiliation Missing  Author Use of Honorific  \\\n",
       "0                      NaN                  NaN                      NaN   \n",
       "1                      0.0                  1.0                      0.0   \n",
       "2                      0.0                  0.0                      0.0   \n",
       "3                      0.0                  1.0                      0.0   \n",
       "4                      1.0                  1.0                      NaN   \n",
       "\n",
       "   Author Name in All Caps  Non-ASCII Characters  Multilingual Abstract  \\\n",
       "0                      NaN                   NaN                    NaN   \n",
       "1                      1.0                   0.0                    NaN   \n",
       "2                      0.0                   0.0                    NaN   \n",
       "3                      0.0                   0.0                    NaN   \n",
       "4                      NaN                   NaN                    NaN   \n",
       "\n",
       "   Abstract Language Match  Article-Journal Language Match  \\\n",
       "0                      NaN                               0   \n",
       "1                      NaN                               1   \n",
       "2                      NaN                               1   \n",
       "3                      NaN                               1   \n",
       "4                      NaN                               0   \n",
       "\n",
       "   Title Language Match  Total Errors  \n",
       "0                   NaN           4.0  \n",
       "1                   NaN           5.0  \n",
       "2                   0.0           3.0  \n",
       "3                   0.0           4.0  \n",
       "4                   1.0           6.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Taking a look at the df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf560bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(output_dir / '03_labeled_data.parquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
